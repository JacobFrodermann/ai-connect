import pandas as pd
from textblob import TextBlob
from typing import List, TypedDict, Any, Set, Optional

# --- Core Data Structures (Updated for Parser needs) ---

class Person(TypedDict):
    properties: dict[str, str]

class Solution:
    var: List[Person] = []

class Constraint:
    """
    Base interface for all logical rules.
    """
    def isSatisfied(self, solution: Solution) -> bool:
        return True

class ValueConstraint(Constraint):
    """
    A concrete constraint generated by the Parser.
    Represents a direct link found in text, e.g., 'The Englishman lives in the red house'.
    """
    def __init__(self, subject: str, value: str):
        self.subject = subject
        self.value = value

    def isSatisfied(self, solution: Solution) -> bool:
        # Logic to be implemented by Solver team
        return True
    
    def __repr__(self):
        return f"Constraint: [{self.subject}] <--> [{self.value}]"

class RawProblem:
    """
    Holds the raw data ingested from the dataset.
    Updated to include 'text' which comes from the 'puzzle' column in ZebraLogicBench.
    """
    ID: str
    text: str 

    def __init__(self, id: str, text: str):
        self.ID = id
        self.text = text

class ParsedProblem:
    """
    The structured output produced by the Parser.
    Updated to store the extracted constraints and entities.
    """
    ID: str
    constraints: List[Constraint]
    entities: Set[str] # Valid entities found (e.g., 'Englishman', 'Red', 'Dog')

    def __init__(self, id: str):
        self.ID = id
        self.constraints = []
        self.entities = set()

class Importer:
    def next(self) -> RawProblem:
        # This would read from the 'puzzle' column of the dataset
        pass

# --- THE PARSER (Your Part) ---

class Parser:
    """
    Responsible for converting raw natural language text into structured Constraints
    using an NLP pipeline (Pandas + TextBlob).
    """
    def parse(self, raw: RawProblem) -> ParsedProblem:
        parsed = ParsedProblem(raw.ID)
        
        # 1. Ingestion: Load text into DataFrame for vectorized processing
        # We split by '.' to analyze the puzzle sentence-by-sentence.
        sentences = raw.text.split('.')
        df = pd.DataFrame(sentences, columns=["raw_text"])
        
        # Filter out empty rows caused by splitting
        df = df[df["raw_text"].str.strip() != ""]
        
        # 2. Preprocessing Pipeline
        # Convert to lowercase to standardize (e.g., "Red" -> "red")
        df["processed"] = df["raw_text"].apply(lambda x: " ".join(x.lower().split()))
        
        # Clean punctuation but preserve sentence structure
        # regex=True ensures we remove special chars like '!', ',' but keep spaces
        df["processed"] = df["processed"].str.replace(r"[^\w\s]", "", regex=True)
        
        # Note: We intentionally skip Stopword Removal.
        # Logic keywords like "not", "next to", "same" are crucial for puzzles.

        # 3. Feature Extraction (POS Tagging)
        # We use TextBlob to identify parts of speech:
        # NN (Noun), JJ (Adjective), VB (Verb)
        try:
            df["tags"] = df["processed"].apply(lambda x: TextBlob(x).tags)
        except Exception as e:
            print(f"NLP Error: {e}. Ensure TextBlob corpora is downloaded.")
            return parsed

        # 4. Logic Extraction Loop
        # Iterate through processed sentences to generate Constraints
        for index, row in df.iterrows():
            self._extract_constraints(row["tags"], parsed)
            
        return parsed

    def _extract_constraints(self, tags: List[tuple], parsed_obj: ParsedProblem):
        """
        Analyzes POS tags to extract logical relationships.
        """
        # Extract potential entities (Nouns) and properties (Adjectives/Nouns)
        # NN* captures NN, NNS, NNP, NNPS
        nouns = [word for word, tag in tags if tag.startswith('NN')]
        adjectives = [word for word, tag in tags if tag.startswith('JJ')]
        
        # Heuristic 1: Attribution (Subject + Adjective)
        # Example: "The Englishman(NN) lives in the Red(JJ) house."
        if len(nouns) >= 1 and len(adjectives) >= 1:
            subject = nouns[0]
            value = adjectives[0]
            self._add_constraint(parsed_obj, subject, value)

        # Heuristic 2: Direct Association (Noun + Noun)
        # Example: "The Spaniard(NN) owns the Dog(NN)."
        elif len(nouns) >= 2:
            subject = nouns[0]
            value = nouns[1]
            # Avoid self-referencing (e.g., "The house is a house")
            if subject != value:
                self._add_constraint(parsed_obj, subject, value)

    def _add_constraint(self, parsed_obj: ParsedProblem, entity1: str, entity2: str):
        """
        Helper to add a constraint and register entities.
        """
        parsed_obj.entities.add(entity1)
        parsed_obj.entities.add(entity2)
        parsed_obj.constraints.append(ValueConstraint(entity1, entity2))

class Solver:
    def solve(self, problem: ParsedProblem) -> Solution:
        pass

# --- verification (Not part of the class file, but for testing) ---
if __name__ == "__main__":
    # Simulating data from the ZebraLogicBench 'puzzle' column
    sample_puzzle_text = "There are 5 houses. The Englishman lives in the red house. The Spaniard owns the dog."
    
    raw = RawProblem("lgp-test-5x6-16", sample_puzzle_text)
    parser = Parser()
    result = parser.parse(raw)
    
    print(f"Parsed ID: {result.ID}")
    print(f"Entities: {result.entities}")
    print(f"Constraints: {result.constraints}")
